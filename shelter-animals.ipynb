{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26729, 10), (11456, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeSubtype    50.925961\n",
       "Name              28.773991\n",
       "AgeuponOutcome     0.067343\n",
       "SexuponOutcome     0.003741\n",
       "Color              0.000000\n",
       "Breed              0.000000\n",
       "AnimalType         0.000000\n",
       "OutcomeType        0.000000\n",
       "DateTime           0.000000\n",
       "AnimalID           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_percent = train.apply(pd.isnull, axis = 0).sum() / train.shape[0] * 100\n",
    "empty_percent.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Name</th>\n",
       "      <th>OutcomeSubtype</th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365.0</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "      <td>Brown/White</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>Hambone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Return_to_owner</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365.0</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Cream Tabby</td>\n",
       "      <td>2013-10-13 12:44:00</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Suffering</td>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730.0</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "      <td>Blue/White</td>\n",
       "      <td>2015-01-31 12:28:00</td>\n",
       "      <td>Pearce</td>\n",
       "      <td>Foster</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgeuponOutcome AnimalType                   Breed        Color  \\\n",
       "0           365.0        Dog   Shetland Sheepdog Mix  Brown/White   \n",
       "1           365.0        Cat  Domestic Shorthair Mix  Cream Tabby   \n",
       "2           730.0        Dog            Pit Bull Mix   Blue/White   \n",
       "\n",
       "              DateTime     Name OutcomeSubtype      OutcomeType  \\\n",
       "0  2014-02-12 18:22:00  Hambone            NaN  Return_to_owner   \n",
       "1  2013-10-13 12:44:00    Emily      Suffering       Euthanasia   \n",
       "2  2015-01-31 12:28:00   Pearce         Foster         Adoption   \n",
       "\n",
       "  SexuponOutcome Train  \n",
       "0  Neutered Male  True  \n",
       "1  Spayed Female  True  \n",
       "2  Neutered Male  True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_dates(val):\n",
    "#     print(float(val.split(\" \")[0]) * 365)\n",
    "#     print(val)\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    \n",
    "    num_val = float(val.split(\" \")[0])\n",
    "    if \"year\" in val:\n",
    "        return num_val * 365\n",
    "    elif \"month\" in val:\n",
    "        return num_val * 30.5\n",
    "    elif \"week\" in val:\n",
    "        return num_val * 7\n",
    "\n",
    "\n",
    "def transform_dataset(df, columns_to_dropna=[\"AgeuponOutcome\", \"SexuponOutcome\"]):\n",
    "    result = df\n",
    "#     result = df.dropna(subset=columns_to_dropna, axis=0)\n",
    "    result.loc[:, \"AgeuponOutcome\"] = result.loc[:, \"AgeuponOutcome\"].apply(transform_dates)\n",
    "    result[\"AgeuponOutcome\"].fillna(result['AgeuponOutcome'].dropna().mean(), inplace = True)\n",
    "    return result\n",
    "\n",
    "train[\"Train\"] = True\n",
    "test[\"Train\"] = False\n",
    "train.drop('AnimalID', axis=1, inplace=True)\n",
    "test.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "dataset = pd.concat([train, test])\n",
    "dataset = transform_dataset(dataset)\n",
    "# dataset.drop(['AnimalID', 'ID'], axis=1, inplace=True)\n",
    "# test_t = transform_dataset(test)\n",
    "dataset.reset_index()\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38185, 10), (11456, 10), (11456, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape, dataset[dataset['Train'] == False].shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any empty values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgeuponOutcome    False\n",
       "AnimalType        False\n",
       "Breed             False\n",
       "Color             False\n",
       "DateTime          False\n",
       "Name               True\n",
       "OutcomeSubtype     True\n",
       "OutcomeType        True\n",
       "SexuponOutcome     True\n",
       "Train             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split all mixed breeds. Breed column contains a low number of strings like \"Black/Tan Hound Mix\" so we will remove colors fom those so we can split all values as we wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# First we remove \"Mix\" from all breeds and add additional categorical variable to the dataset\n",
    "dataset[\"Mix\"] = False\n",
    "dataset.loc[dataset[\"Breed\"].str.contains(\"Mix\"), \"Mix\"] = True\n",
    "\n",
    "# DEPRECATRED - those features seem too be better removed\n",
    "# breeds = dataset[\"Breed\"].apply(lambda x: x.split(\" Mix\")[0])\n",
    "\n",
    "# # Next we remove all of the colors which cause problems when we try to split mixed breeds \n",
    "# breeds = breeds.apply(lambda x: re.sub('Black\\s?|Tan\\s?', '', x))\n",
    "\n",
    "# # After that let's remove dirty substrings left from previous replacements\n",
    "# breeds = breeds.apply(lambda x: re.sub('^/', '', x))\n",
    "# breeds = breeds.str.replace(\"//\", \"\")\n",
    "\n",
    "# # Finally, lets split the breeds and modify out dataset\n",
    "# breeds = breeds.apply(lambda x: pd.Series(x.split(\"/\")))\n",
    "# breeds.columns = ['Breed', 'SecondaryBreed']\n",
    "\n",
    "dataset.drop('Breed', inplace=True, axis = 1)\n",
    "# dataset = pd.concat([dataset, breeds], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'breeds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b2e6fc640c70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbreeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'breeds' is not defined"
     ]
    }
   ],
   "source": [
    "breeds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Color</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Name</th>\n",
       "      <th>OutcomeSubtype</th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>Train</th>\n",
       "      <th>Mix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365.0</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Brown/White</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>Hambone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Return_to_owner</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365.0</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Cream Tabby</td>\n",
       "      <td>2013-10-13 12:44:00</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Suffering</td>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730.0</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Blue/White</td>\n",
       "      <td>2015-01-31 12:28:00</td>\n",
       "      <td>Pearce</td>\n",
       "      <td>Foster</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgeuponOutcome AnimalType        Color             DateTime     Name  \\\n",
       "0           365.0        Dog  Brown/White  2014-02-12 18:22:00  Hambone   \n",
       "1           365.0        Cat  Cream Tabby  2013-10-13 12:44:00    Emily   \n",
       "2           730.0        Dog   Blue/White  2015-01-31 12:28:00   Pearce   \n",
       "\n",
       "  OutcomeSubtype      OutcomeType SexuponOutcome Train   Mix  \n",
       "0            NaN  Return_to_owner  Neutered Male  True  True  \n",
       "1      Suffering       Euthanasia  Spayed Female  True  True  \n",
       "2         Foster         Adoption  Neutered Male  True  True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset.reset_index(inplace=True)\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split DateTime to several features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import *\n",
    "\n",
    "dates = dataset['DateTime'].apply(lambda x : datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# def time_of_day(hour):\n",
    "#     if hour > 7 and hour <= 11:\n",
    "#         return \"morning\"\n",
    "#     elif hour > 11 and hour <= 18:\n",
    "#         return \"day\"\n",
    "#     elif hour > 18 and hour <= 22:\n",
    "#         return \"evening\"\n",
    "#     else:\n",
    "#         return \"night\"\n",
    "\n",
    "dataset[\"Year\"] = dates.apply(lambda x: x.year)\n",
    "dataset[\"Month\"] = dates.apply(lambda x: x.month)\n",
    "dataset[\"Hour\"] = dates.apply(lambda x: x.hour)\n",
    "dataset[\"Weekday\"] = dates.apply(lambda x: x.weekday())\n",
    "# dataset[\"TimeOfDay\"] = dates.apply(lambda x: time_of_day(x.hour))\n",
    "dataset.head(5)\n",
    "dataset.drop(\"DateTime\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name can be converted to HasName categorical feature which will be more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset['HasName'] = dataset['Name'].isnull()\n",
    "dataset.drop(['Name', 'OutcomeSubtype'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will probaby be way to much features for colors, so we will transform them too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(dataset['Color']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 quantitative features instead of 411, nice improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "split_colors = pd.DataFrame(dataset['Color'].str.split('/').tolist(), columns=[\"Color1\", \"Color2\"])\n",
    "dataset.drop('Color', axis = 1, inplace=True)\n",
    "\n",
    "l_enc = LabelEncoder()\n",
    "split_colors['Color2'].fillna(\"None\", inplace=True)\n",
    "split_colors['Color1'] = l_enc.fit_transform(split_colors['Color1'])\n",
    "split_colors['Color2'] = l_enc.fit_transform(split_colors['Color2'])\n",
    "dataset = dataset.join(split_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutered Male    14014\n",
       "Spayed Female    12633\n",
       "Intact Female     5004\n",
       "Intact Male       4985\n",
       "Unknown           1548\n",
       "Name: SexuponOutcome, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['SexuponOutcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset['SexuponOutcome'].fillna('Neutered Male', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sex = pd.DataFrame(dataset['SexuponOutcome'].str.split(\" \").tolist(), columns=[\"Sterialized\", \"Sex\"])\n",
    "sex.head(2)\n",
    "dataset = dataset.join(sex)\n",
    "dataset.drop('SexuponOutcome', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert AnimalType to boolean feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset['IsDog'] = dataset['AnimalType'].apply(lambda x: x == \"Dog\")\n",
    "dataset['IsMale'] = dataset['Sex'].apply(lambda x: x == \"Male\")\n",
    "dataset.drop(['AnimalType', 'Sex'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>Train</th>\n",
       "      <th>Mix</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>HasName</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>IsDog</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Sterialized_Intact</th>\n",
       "      <th>Sterialized_Neutered</th>\n",
       "      <th>Sterialized_Spayed</th>\n",
       "      <th>Sterialized_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365.0</td>\n",
       "      <td>Return_to_owner</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>305.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365.0</td>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgeuponOutcome      OutcomeType  Train   Mix  Year  Month  Hour  Weekday  \\\n",
       "0           365.0  Return_to_owner   True  True  2014      2    18        2   \n",
       "0           305.0              NaN  False  True  2015     10    12        0   \n",
       "1           365.0       Euthanasia   True  True  2013     10    12        6   \n",
       "\n",
       "  HasName  Color1  Color2  IsDog IsMale  Sterialized_Intact  \\\n",
       "0   False      15      44   True   True                 0.0   \n",
       "0   False      15      44   True   True                 0.0   \n",
       "1   False      26      30  False  False                 1.0   \n",
       "\n",
       "   Sterialized_Neutered  Sterialized_Spayed  Sterialized_Unknown  \n",
       "0                   1.0                 0.0                  0.0  \n",
       "0                   1.0                 0.0                  0.0  \n",
       "1                   0.0                 0.0                  0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Sterialized']\n",
    "dataset_d = pd.get_dummies(dataset, columns = cols)\n",
    "dataset_d.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OutcomeType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return_to_owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OutcomeType\n",
       "0  Return_to_owner"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_d.drop(['index'], axis=1, inplace=True)\n",
    "dataset_d.loc[:, dataset_d.columns.str.contains(\"OutcomeType\")].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit XGBoost model on full dataset in order to perform feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdubovikov/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kdubovikov/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((26729, 15), (11456, 15))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "train = dataset_d[dataset['Train'] == True]\n",
    "test = dataset_d[dataset['Train'] == False]\n",
    "\n",
    "train.drop('Train', axis=1, inplace=True)\n",
    "test.drop('Train', axis=1, inplace=True)\n",
    "\n",
    "train_x = train.loc[:, train.columns.difference([\"OutcomeType\"])]\n",
    "train_y = train.loc[:, \"OutcomeType\"]\n",
    "\n",
    "# train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.3)\n",
    "\n",
    "test_x = test.loc[:, test.columns.difference([\"OutcomeType\"])]\n",
    "\n",
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error estimates for the full model will help us not to throw off important features during selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.384564</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.337657</td>\n",
       "      <td>0.003144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371132</td>\n",
       "      <td>0.011231</td>\n",
       "      <td>0.320728</td>\n",
       "      <td>0.002881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.368514</td>\n",
       "      <td>0.010524</td>\n",
       "      <td>0.316202</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.364174</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.311908</td>\n",
       "      <td>0.003598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.360208</td>\n",
       "      <td>0.009688</td>\n",
       "      <td>0.309486</td>\n",
       "      <td>0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.360320</td>\n",
       "      <td>0.010197</td>\n",
       "      <td>0.306998</td>\n",
       "      <td>0.003276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.360320</td>\n",
       "      <td>0.010291</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.003393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.360582</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.303781</td>\n",
       "      <td>0.003818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.359422</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.301237</td>\n",
       "      <td>0.004059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.359572</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.299852</td>\n",
       "      <td>0.003193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "0          0.384564         0.009673           0.337657          0.003144\n",
       "1          0.371132         0.011231           0.320728          0.002881\n",
       "2          0.368514         0.010524           0.316202          0.002632\n",
       "3          0.364174         0.009378           0.311908          0.003598\n",
       "4          0.360208         0.009688           0.309486          0.004060\n",
       "5          0.360320         0.010197           0.306998          0.003276\n",
       "6          0.360320         0.010291           0.305932          0.003393\n",
       "7          0.360582         0.010340           0.303781          0.003818\n",
       "8          0.359422         0.011482           0.301237          0.004059\n",
       "9          0.359572         0.010973           0.299852          0.003193"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# xgb_param_dist = {\"n_estimators\"     : 150,\n",
    "#                   \"max_depth\"        : 8,\n",
    "#                   \"learning_rate\"    : 0.1,\n",
    "#                   \"colsample_bytree\" : 0.8}\n",
    "\n",
    "xgb_param_dist = {\"n_estimators\"     : 200,\n",
    "                  \"max_depth\"        : 10,\n",
    "                  \"learning_rate\"    : 0.08,\n",
    "                  \"colsample_bytree\" : 0.7,\n",
    "                  \"objective\"        : \"multi:softmax\",\n",
    "                  \"num_class\" : 5}\n",
    "\n",
    "enc = LabelEncoder()\n",
    "enc.fit(train_y)\n",
    "train_yt = enc.transform(train_y)\n",
    "xgb.cv(xgb_param_dist, xgb.DMatrix(train_x, train_yt), nfold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# xgb_param_dist_sk = \n",
    "# xgb_param_dist.pop(\"num_class\", None)\n",
    "# cf = xgb.Booster(**xgb_param_dist)\n",
    "# %time cf.fit(train_x, train_y)\n",
    "\n",
    "bst = xgb.train(xgb_param_dist, xgb.DMatrix(train_x, train_yt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get feature importance map and see top 100 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.booster().save_model('full.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2838, 2326, 2128, 1690, 1616, 1492,  866,  458,  451,  386,  336,\n",
       "        322,  315,  179,  116])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscores = bst.get_fscore()\n",
    "# fscores = bst.get_fscore()\n",
    "np.sort(list(fscores.values()))[::-1][0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature selection based on a `fscore` threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% features left\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "filtered_fscores = {k: v for k, v in fscores.items() if v > 0}\n",
    "\n",
    "print(\"{0:1.2f}% features left\".format((len(filtered_fscores) / len(fscores)) * 100))\n",
    "# model = SelectFromModel(cf ,prefit=True)\n",
    "# train_xr = model.transform(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.407946</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.360115</td>\n",
       "      <td>0.002929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.376108</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>0.329043</td>\n",
       "      <td>0.002310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.372816</td>\n",
       "      <td>0.008835</td>\n",
       "      <td>0.321636</td>\n",
       "      <td>0.004978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.368551</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.314003</td>\n",
       "      <td>0.005295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.366044</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.308906</td>\n",
       "      <td>0.004250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.366456</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.307868</td>\n",
       "      <td>0.005097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.365932</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.306184</td>\n",
       "      <td>0.006489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.364847</td>\n",
       "      <td>0.010819</td>\n",
       "      <td>0.304173</td>\n",
       "      <td>0.005556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.363463</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.301143</td>\n",
       "      <td>0.005665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.009493</td>\n",
       "      <td>0.299310</td>\n",
       "      <td>0.006536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.363912</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.296700</td>\n",
       "      <td>0.006098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.362565</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.294970</td>\n",
       "      <td>0.006220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.362415</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>0.293202</td>\n",
       "      <td>0.006140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.362378</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.291144</td>\n",
       "      <td>0.004564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.362266</td>\n",
       "      <td>0.009519</td>\n",
       "      <td>0.289564</td>\n",
       "      <td>0.004633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "0           0.407946         0.011191           0.360115          0.002929\n",
       "1           0.376108         0.009387           0.329043          0.002310\n",
       "2           0.372816         0.008835           0.321636          0.004978\n",
       "3           0.368551         0.008986           0.314003          0.005295\n",
       "4           0.366044         0.011464           0.308906          0.004250\n",
       "5           0.366456         0.011807           0.307868          0.005097\n",
       "6           0.365932         0.010996           0.306184          0.006489\n",
       "7           0.364847         0.010819           0.304173          0.005556\n",
       "8           0.363463         0.009620           0.301143          0.005665\n",
       "9           0.363986         0.009493           0.299310          0.006536\n",
       "10          0.363912         0.010605           0.296700          0.006098\n",
       "11          0.362565         0.010687           0.294970          0.006220\n",
       "12          0.362415         0.009617           0.293202          0.006140\n",
       "13          0.362378         0.009437           0.291144          0.004564\n",
       "14          0.362266         0.009519           0.289564          0.004633"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_cols = list(filtered_fscores.keys())\n",
    "train_xr = train_x[filtered_cols]\n",
    "# val_xr = val_x[filtered_cols]\n",
    "test_xr = test_x[filtered_cols]\n",
    "\n",
    "# cfr = xgb.XGBClassifier(**xgb_param_dist)\n",
    "# cfr.fit(train_xr, train_y)\n",
    "xgb.cv(xgb_param_dist, xgb.DMatrix(train_xr, train_yt), 15, nfold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "xgb_param_dist = {\"n_estimators\" : np.arange(10, 250, 10),\n",
    "                    \"max_depth\": sp_randint(2, 31),\n",
    "                    \"learning_rate\" : uniform(loc = 0.01, scale=0.2),\n",
    "                    \"colsample_bytree\" : uniform(loc = 0.3, scale = 0.7),\n",
    "                    \"subsample\" : uniform(loc = 0.0, scale = 0.7),\n",
    "                    \"objective\" : \"multi:softmax\"}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "n_iter_search = 30\n",
    "\n",
    "xgb_random_search = RandomizedSearchCV(xgb_clf, param_distributions = xgb_param_dist,\n",
    "                                       n_iter = n_iter_search, random_state = 123, n_jobs = 8, verbose = 1)\n",
    "%time xgb_random_search.fit(train_xr, train_yt)\n",
    "                                       \n",
    "xgb_clf = xgb_random_search.best_estimator_\n",
    "\n",
    "print(\"Best randomized search score - %s\" % xgb_random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_clf.booster().save_model('random_search_best_est.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "best_m = xgb.Booster({'nthread' : 8}) #init model\n",
    "best_m.load_model('/home/kdubovikov/MEGA/random_search_best_est.model') # load data\n",
    "\n",
    "pred = best_m.predict(xgb.DMatrix(test_x))\n",
    "enc.inverse_transform(pred.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 284 ms, total: 19.4 s\n",
      "Wall time: 2.57 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.439409</td>\n",
       "      <td>0.026508</td>\n",
       "      <td>0.384508</td>\n",
       "      <td>0.021507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397657</td>\n",
       "      <td>0.016269</td>\n",
       "      <td>0.338378</td>\n",
       "      <td>0.009976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.384152</td>\n",
       "      <td>0.013520</td>\n",
       "      <td>0.324451</td>\n",
       "      <td>0.005137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.372778</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>0.317081</td>\n",
       "      <td>0.003020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.369748</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>0.311843</td>\n",
       "      <td>0.004166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.367690</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.308064</td>\n",
       "      <td>0.004302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.365371</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.307653</td>\n",
       "      <td>0.004837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.364248</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.305071</td>\n",
       "      <td>0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.363238</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.304454</td>\n",
       "      <td>0.005292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.363238</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.303659</td>\n",
       "      <td>0.005369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "0          0.439409         0.026508           0.384508          0.021507\n",
       "1          0.397657         0.016269           0.338378          0.009976\n",
       "2          0.384152         0.013520           0.324451          0.005137\n",
       "3          0.372778         0.010664           0.317081          0.003020\n",
       "4          0.369748         0.009544           0.311843          0.004166\n",
       "5          0.367690         0.010728           0.308064          0.004302\n",
       "6          0.365371         0.007909           0.307653          0.004837\n",
       "7          0.364248         0.008385           0.305071          0.004907\n",
       "8          0.363238         0.009040           0.304454          0.005292\n",
       "9          0.363238         0.008500           0.303659          0.005369"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params ={'colsample_bytree': 0.7082178433723527,\n",
    "             'learning_rate': 0.06,\n",
    "             'max_depth': 10,\n",
    "             'n_estimators': 50,\n",
    "             'num_class': 5,\n",
    "             'objective': 'multi:softprob',\n",
    "             'subsample': 0.8}\n",
    "# best_params['num_class']= 5\n",
    "# best_params['objective'] = 'multi:softmax'\n",
    "\n",
    "filtered_fscores_t = {k: v for k, v in fscores.items() if v > 0}\n",
    "filtered_cols_t = list(filtered_fscores_t.keys())\n",
    "train_xrt = train_x[filtered_cols_t]\n",
    "# val_xr = val_x[filtered_cols]\n",
    "test_xrt = test_x[filtered_cols_t]\n",
    "\n",
    "# cfr = xgb.XGBClassifier(**xgb_param_dist)\n",
    "# cfr.fit(train_xr, train_y)\n",
    "# xgb.cv(best_params, xgb.DMatrix(train_x, train_yt), 15, nfold=5)\n",
    "%time xgb.cv(best_params, xgb.DMatrix(train_xr, train_yt), nfold=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 s, sys: 124 ms, total: 4.64 s\n",
      "Wall time: 634 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.12148891,  0.12329598,  0.12351845, ...,  0.46134725,\n",
       "        0.46157441,  0.4620828 ], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time booster = xgb.train(best_params, xgb.DMatrix(train_xr, train_yt))\n",
    "np.unique(booster.predict(xgb.DMatrix(test_xr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This wont work properly with softprob\n",
    "preds = booster.predict(xgb.DMatrix(test_xr))\n",
    "oh_results = enc.inverse_transform(preds.astype(int))\n",
    "np.unique(oh_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oh_enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "results = oh_enc.fit_transform(preds.reshape(-1, 1))\n",
    "results = results.astype(int)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.68 s, sys: 72 ms, total: 4.76 s\n",
      "Wall time: 653 ms\n",
      "CPU times: user 4.9 s, sys: 76 ms, total: 4.98 s\n",
      "Wall time: 630 ms\n",
      "CPU times: user 4.82 s, sys: 120 ms, total: 4.94 s\n",
      "Wall time: 625 ms\n",
      "CPU times: user 4.97 s, sys: 80 ms, total: 5.05 s\n",
      "Wall time: 647 ms\n",
      "CPU times: user 4.87 s, sys: 76 ms, total: 4.95 s\n",
      "Wall time: 626 ms\n",
      "CPU times: user 4.8 s, sys: 96 ms, total: 4.89 s\n",
      "Wall time: 619 ms\n",
      "CPU times: user 4.85 s, sys: 96 ms, total: 4.94 s\n",
      "Wall time: 626 ms\n",
      "CPU times: user 4.93 s, sys: 24 ms, total: 4.96 s\n",
      "Wall time: 628 ms\n",
      "CPU times: user 4.9 s, sys: 100 ms, total: 5 s\n",
      "Wall time: 635 ms\n",
      "CPU times: user 4.91 s, sys: 92 ms, total: 5 s\n",
      "Wall time: 637 ms\n",
      "CPU times: user 4.83 s, sys: 72 ms, total: 4.9 s\n",
      "Wall time: 620 ms\n",
      "CPU times: user 4.86 s, sys: 96 ms, total: 4.96 s\n",
      "Wall time: 627 ms\n",
      "CPU times: user 5.09 s, sys: 116 ms, total: 5.21 s\n",
      "Wall time: 666 ms\n",
      "CPU times: user 5.84 s, sys: 124 ms, total: 5.96 s\n",
      "Wall time: 780 ms\n",
      "CPU times: user 5.89 s, sys: 148 ms, total: 6.04 s\n",
      "Wall time: 791 ms\n",
      "CPU times: user 5.88 s, sys: 136 ms, total: 6.01 s\n",
      "Wall time: 795 ms\n",
      "CPU times: user 7.74 s, sys: 160 ms, total: 7.9 s\n",
      "Wall time: 1.1 s\n",
      "CPU times: user 5.41 s, sys: 120 ms, total: 5.53 s\n",
      "Wall time: 720 ms\n",
      "CPU times: user 5.29 s, sys: 72 ms, total: 5.36 s\n",
      "Wall time: 690 ms\n",
      "CPU times: user 5.58 s, sys: 156 ms, total: 5.74 s\n",
      "Wall time: 748 ms\n",
      "CPU times: user 5.04 s, sys: 108 ms, total: 5.14 s\n",
      "Wall time: 654 ms\n",
      "CPU times: user 4.95 s, sys: 60 ms, total: 5.01 s\n",
      "Wall time: 637 ms\n",
      "CPU times: user 5 s, sys: 112 ms, total: 5.11 s\n",
      "Wall time: 648 ms\n",
      "CPU times: user 4.95 s, sys: 100 ms, total: 5.05 s\n",
      "Wall time: 640 ms\n",
      "CPU times: user 4.96 s, sys: 68 ms, total: 5.02 s\n",
      "Wall time: 638 ms\n",
      "CPU times: user 5.03 s, sys: 64 ms, total: 5.1 s\n",
      "Wall time: 647 ms\n",
      "CPU times: user 4.96 s, sys: 84 ms, total: 5.04 s\n",
      "Wall time: 640 ms\n",
      "CPU times: user 4.95 s, sys: 72 ms, total: 5.02 s\n",
      "Wall time: 638 ms\n",
      "CPU times: user 5 s, sys: 52 ms, total: 5.05 s\n",
      "Wall time: 641 ms\n",
      "CPU times: user 5.12 s, sys: 52 ms, total: 5.17 s\n",
      "Wall time: 660 ms\n",
      "CPU times: user 5.02 s, sys: 108 ms, total: 5.12 s\n",
      "Wall time: 652 ms\n",
      "CPU times: user 5 s, sys: 72 ms, total: 5.07 s\n",
      "Wall time: 643 ms\n",
      "CPU times: user 4.88 s, sys: 120 ms, total: 5 s\n",
      "Wall time: 639 ms\n",
      "CPU times: user 5.01 s, sys: 80 ms, total: 5.09 s\n",
      "Wall time: 646 ms\n",
      "CPU times: user 4.98 s, sys: 104 ms, total: 5.08 s\n",
      "Wall time: 647 ms\n",
      "CPU times: user 5.03 s, sys: 116 ms, total: 5.15 s\n",
      "Wall time: 653 ms\n",
      "CPU times: user 5.04 s, sys: 104 ms, total: 5.15 s\n",
      "Wall time: 654 ms\n",
      "CPU times: user 4.94 s, sys: 76 ms, total: 5.01 s\n",
      "Wall time: 636 ms\n",
      "CPU times: user 8.55 s, sys: 272 ms, total: 8.82 s\n",
      "Wall time: 1.26 s\n",
      "CPU times: user 6.49 s, sys: 124 ms, total: 6.62 s\n",
      "Wall time: 881 ms\n",
      "CPU times: user 5.4 s, sys: 156 ms, total: 5.55 s\n",
      "Wall time: 719 ms\n",
      "CPU times: user 5.02 s, sys: 84 ms, total: 5.1 s\n",
      "Wall time: 649 ms\n",
      "CPU times: user 5.4 s, sys: 88 ms, total: 5.49 s\n",
      "Wall time: 705 ms\n",
      "CPU times: user 5.18 s, sys: 176 ms, total: 5.36 s\n",
      "Wall time: 685 ms\n",
      "CPU times: user 5.16 s, sys: 128 ms, total: 5.29 s\n",
      "Wall time: 682 ms\n",
      "CPU times: user 4.96 s, sys: 108 ms, total: 5.07 s\n",
      "Wall time: 651 ms\n",
      "CPU times: user 4.88 s, sys: 96 ms, total: 4.97 s\n",
      "Wall time: 630 ms\n",
      "CPU times: user 5.18 s, sys: 108 ms, total: 5.29 s\n",
      "Wall time: 675 ms\n",
      "CPU times: user 4.96 s, sys: 72 ms, total: 5.03 s\n",
      "Wall time: 637 ms\n",
      "CPU times: user 4.94 s, sys: 92 ms, total: 5.04 s\n",
      "Wall time: 646 ms\n",
      "CPU times: user 4.93 s, sys: 116 ms, total: 5.04 s\n",
      "Wall time: 638 ms\n",
      "CPU times: user 4.96 s, sys: 76 ms, total: 5.04 s\n",
      "Wall time: 637 ms\n",
      "CPU times: user 4.98 s, sys: 100 ms, total: 5.08 s\n",
      "Wall time: 643 ms\n",
      "CPU times: user 4.96 s, sys: 84 ms, total: 5.04 s\n",
      "Wall time: 638 ms\n",
      "CPU times: user 5.1 s, sys: 104 ms, total: 5.21 s\n",
      "Wall time: 664 ms\n",
      "CPU times: user 4.95 s, sys: 116 ms, total: 5.06 s\n",
      "Wall time: 641 ms\n",
      "CPU times: user 4.96 s, sys: 100 ms, total: 5.06 s\n",
      "Wall time: 641 ms\n",
      "CPU times: user 4.94 s, sys: 116 ms, total: 5.05 s\n",
      "Wall time: 639 ms\n",
      "CPU times: user 5 s, sys: 52 ms, total: 5.06 s\n",
      "Wall time: 640 ms\n",
      "CPU times: user 4.93 s, sys: 88 ms, total: 5.02 s\n",
      "Wall time: 635 ms\n",
      "CPU times: user 4.86 s, sys: 100 ms, total: 4.96 s\n",
      "Wall time: 628 ms\n",
      "CPU times: user 4.88 s, sys: 64 ms, total: 4.95 s\n",
      "Wall time: 626 ms\n",
      "CPU times: user 4.97 s, sys: 108 ms, total: 5.08 s\n",
      "Wall time: 646 ms\n",
      "CPU times: user 4.9 s, sys: 92 ms, total: 4.99 s\n",
      "Wall time: 631 ms\n",
      "CPU times: user 4.88 s, sys: 60 ms, total: 4.94 s\n",
      "Wall time: 631 ms\n",
      "CPU times: user 4.94 s, sys: 68 ms, total: 5.01 s\n",
      "Wall time: 634 ms\n",
      "CPU times: user 4.97 s, sys: 116 ms, total: 5.08 s\n",
      "Wall time: 645 ms\n",
      "CPU times: user 5.05 s, sys: 24 ms, total: 5.08 s\n",
      "Wall time: 643 ms\n",
      "CPU times: user 4.88 s, sys: 132 ms, total: 5.01 s\n",
      "Wall time: 634 ms\n",
      "CPU times: user 4.98 s, sys: 100 ms, total: 5.08 s\n",
      "Wall time: 643 ms\n",
      "CPU times: user 4.96 s, sys: 48 ms, total: 5 s\n",
      "Wall time: 636 ms\n",
      "CPU times: user 5.03 s, sys: 80 ms, total: 5.11 s\n",
      "Wall time: 649 ms\n",
      "CPU times: user 4.95 s, sys: 76 ms, total: 5.03 s\n",
      "Wall time: 636 ms\n",
      "CPU times: user 4.93 s, sys: 108 ms, total: 5.04 s\n",
      "Wall time: 638 ms\n",
      "CPU times: user 4.93 s, sys: 100 ms, total: 5.03 s\n",
      "Wall time: 637 ms\n",
      "CPU times: user 4.92 s, sys: 96 ms, total: 5.01 s\n",
      "Wall time: 635 ms\n",
      "CPU times: user 5.03 s, sys: 72 ms, total: 5.1 s\n",
      "Wall time: 647 ms\n",
      "CPU times: user 4.98 s, sys: 72 ms, total: 5.06 s\n",
      "Wall time: 640 ms\n",
      "CPU times: user 4.97 s, sys: 140 ms, total: 5.11 s\n",
      "Wall time: 648 ms\n",
      "CPU times: user 4.95 s, sys: 84 ms, total: 5.03 s\n",
      "Wall time: 637 ms\n",
      "CPU times: user 4.98 s, sys: 52 ms, total: 5.03 s\n",
      "Wall time: 639 ms\n",
      "CPU times: user 4.88 s, sys: 104 ms, total: 4.99 s\n",
      "Wall time: 632 ms\n",
      "CPU times: user 4.95 s, sys: 80 ms, total: 5.03 s\n",
      "Wall time: 637 ms\n",
      "CPU times: user 4.95 s, sys: 52 ms, total: 5 s\n",
      "Wall time: 633 ms\n",
      "CPU times: user 4.92 s, sys: 76 ms, total: 5 s\n",
      "Wall time: 633 ms\n",
      "CPU times: user 4.9 s, sys: 92 ms, total: 4.99 s\n",
      "Wall time: 631 ms\n",
      "CPU times: user 4.94 s, sys: 100 ms, total: 5.04 s\n",
      "Wall time: 638 ms\n",
      "CPU times: user 4.89 s, sys: 68 ms, total: 4.96 s\n",
      "Wall time: 628 ms\n",
      "CPU times: user 4.9 s, sys: 72 ms, total: 4.97 s\n",
      "Wall time: 628 ms\n",
      "CPU times: user 4.96 s, sys: 68 ms, total: 5.03 s\n",
      "Wall time: 637 ms\n",
      "CPU times: user 4.92 s, sys: 52 ms, total: 4.97 s\n",
      "Wall time: 629 ms\n",
      "CPU times: user 4.89 s, sys: 112 ms, total: 5 s\n",
      "Wall time: 634 ms\n",
      "CPU times: user 4.94 s, sys: 80 ms, total: 5.02 s\n",
      "Wall time: 636 ms\n",
      "CPU times: user 4.93 s, sys: 84 ms, total: 5.01 s\n",
      "Wall time: 635 ms\n",
      "CPU times: user 4.97 s, sys: 52 ms, total: 5.02 s\n",
      "Wall time: 635 ms\n",
      "CPU times: user 4.95 s, sys: 68 ms, total: 5.02 s\n",
      "Wall time: 635 ms\n",
      "CPU times: user 5.02 s, sys: 60 ms, total: 5.08 s\n",
      "Wall time: 643 ms\n",
      "CPU times: user 4.95 s, sys: 48 ms, total: 5 s\n",
      "Wall time: 633 ms\n",
      "CPU times: user 4.94 s, sys: 156 ms, total: 5.1 s\n",
      "Wall time: 648 ms\n",
      "CPU times: user 5 s, sys: 72 ms, total: 5.07 s\n",
      "Wall time: 642 ms\n"
     ]
    }
   ],
   "source": [
    "boosters = np.array([])\n",
    "predictions = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    %time booster = xgb.train(best_params, xgb.DMatrix(train_xr, train_yt))\n",
    "    boosters = np.append(boosters, booster)\n",
    "    predictions.append(booster.predict(xgb.DMatrix(test_xr)))\n",
    "    \n",
    "\n",
    "# %time booster = xgb.train(best_params, xgb.DMatrix(train_xr, train_yt))\n",
    "# np.unique(booster.predict(xgb.DMatrix(test_xr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 332 ms, total: 15.9 s\n",
      "Wall time: 2.26 s\n",
      "CPU times: user 13.5 s, sys: 364 ms, total: 13.9 s\n",
      "Wall time: 2.22 s\n",
      "CPU times: user 13.6 s, sys: 260 ms, total: 13.8 s\n",
      "Wall time: 2.22 s\n",
      "CPU times: user 13.6 s, sys: 264 ms, total: 13.9 s\n",
      "Wall time: 2.01 s\n",
      "CPU times: user 13.4 s, sys: 260 ms, total: 13.7 s\n",
      "Wall time: 2.01 s\n",
      "CPU times: user 13.4 s, sys: 296 ms, total: 13.7 s\n",
      "Wall time: 2.01 s\n",
      "CPU times: user 13.6 s, sys: 308 ms, total: 13.9 s\n",
      "Wall time: 2.01 s\n",
      "CPU times: user 13.5 s, sys: 304 ms, total: 13.8 s\n",
      "Wall time: 2.02 s\n",
      "CPU times: user 13.5 s, sys: 268 ms, total: 13.8 s\n",
      "Wall time: 2.01 s\n",
      "CPU times: user 13.3 s, sys: 336 ms, total: 13.6 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_models = np.array([])\n",
    "# predictions = [] already have those\n",
    "\n",
    "for i in range(0, 10):\n",
    "    rf_clf = RandomForestClassifier(n_estimators=300, criterion='gini', n_jobs=8)\n",
    "    %time rf_clf.fit(train_x, train_yt)\n",
    "    rf_models = np.append(rf_models, rf_clf)\n",
    "    predictions.append(rf_clf.predict_proba(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.mean(predictions, axis = 0)\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "np.unique(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       ..., \n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "results = oh_enc.fit_transform(preds.reshape(-1, 1))\n",
    "results = results.astype(int)\n",
    "results_encoded = results\n",
    "results_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_results = pd.read_csv(\"./test.csv\")\n",
    "# test_results['ID'] = test_results['ID'].astype(int)\n",
    "# final_results = pd.concat([test_results[\"ID\"], pd.DataFrame(results)], axis = 1)\n",
    "final_results = pd.DataFrame(results_encoded)\n",
    "final_results.columns = ['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer']\n",
    "# final_results['Died'] = 0\n",
    "final_results.index.name = 'ID'\n",
    "final_results.index = final_results.index + 1\n",
    "\n",
    "final_results = final_results[['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer']]\n",
    "\n",
    "final_results.to_csv('results_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11456, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
